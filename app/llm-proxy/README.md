# LLMプロキシ

このプロジェクトは、OpenAIとGoogle
Geminiのためのプロキシサーバーであり、Openrouter.aiに似ています。これにより、これらのAPIへのリクエストを安全かつ効率的に転送することができます。

## クイックスタート

TBD


## 基本設計

このプロキシサーバーの基本設計は以下の通りです：

- アーキテクチャ:
FastAPIを使用してHTTPリクエストを処理し、Uvicornを使用してサーバーを実行します。非同期HTTPクライアントとしてhttpxを 使用し、リクエストをOpenAIとGoogle
GeminiのAPIに転送します。
- 認証: リクエストヘッダーにカスタムヘッダー X-API-Key
を使用してAPIキー認証を実装しています。APIキーが .env
ファイルに設定されたものと一致しない場合、リクエストは401
Unauthorizedエラーで拒否されます。
- 環境変数:  .env
ファイルを使用して、APIキーやエンドポイントURLなどの機密情報を管理します。
python-dotenv パッケージを使用して、これらの環境変数をロードします。
- ロギングとエラーハンドリング: Pythonの logging
モジュールを使用して、重要なイベントやエラーをログに記録します。HTTPステータスエラーや予期しないエラーが発生した場合、適切なHTTP例外を発生させ、クライアントに意味のあるエラーメッセージを返します。